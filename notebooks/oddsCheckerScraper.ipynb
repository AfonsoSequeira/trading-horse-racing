{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import UnicodeDammit\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import lxml.html as lh\n",
    "\n",
    "options = Options()\n",
    "user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.517 Safari/537.36'\n",
    "options.add_argument('user-agent={0}'.format(user_agent))\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),\n",
    "                          options=options)\n",
    "driver.get(\"https://www.oddschecker.com/horse-racing/2022-11-21-kempton/13:50/winner\")\n",
    "html_source_code = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "html_soup: BeautifulSoup = BeautifulSoup(html_source_code, 'html.parser')\n",
    "prettyHTML = html_soup.prettify()\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import UnicodeDammit\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import lxml.html as lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide array into sub array for each horse, then \n",
    "#[\"data-o\"]\n",
    "#[data-ew-denom\"]\n",
    "#[\"data-ew-places\"]\n",
    "class OddsCheckerPrice:\n",
    "    \n",
    "    def __init__(self,bookmaker = None, name = None, price = None, ewDenom = None, ewPlaces =  None):\n",
    "        self.name = name\n",
    "        self.bookie = bookmaker\n",
    "        self.price = price\n",
    "        self.ewDenominator = ewDenom\n",
    "        self.ewPlaces = ewPlaces\n",
    "        \n",
    "    def printPrice(self):\n",
    "        print(\"Name: \", self.name,\n",
    "              \" Bookmaker: \", self.bookie,\n",
    "              \" Price: \", self.price,\n",
    "              \" ewDenom: \", self.ewDenominator,\n",
    "              \" ewPlaces: \", self.ewPlaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oddsPortalScraper(prettyHTML, bookMakerList, url, log):\n",
    "    \n",
    "    finalPrices = []\n",
    "    \n",
    "    def split(list_a, chunk_size):\n",
    "        for i in range(0, len(list_a), chunk_size):\n",
    "            yield list_a[i:i + chunk_size]\n",
    "    \n",
    "    soup = BeautifulSoup(prettyHTML)\n",
    "    body = soup.body\n",
    "    pricesHtml = body.find_all(\"td\", class_= lambda value: value and \n",
    "                     (value.startswith(\"bc bs\") or value.startswith(\"np o\") or value.startswith(\"o np\")))\n",
    "    \n",
    "    if log == True:\n",
    "        f = open(url + \".txt\", \"wb\")\n",
    "        f.write(str(body).encode(\"utf-8\"))\n",
    "        f.close()\n",
    "    \n",
    "    pricesHtml = list(split(pricesHtml, len(bookMakerList)))\n",
    "    \n",
    "    namesHtml = body.find_all(\"a\", class_ = \"popup selTxt\")\n",
    "    \n",
    "    horseNames = [x[\"data-name\"] for x in namesHtml]\n",
    "    \n",
    "    for i in range(0, len(pricesHtml)):\n",
    "        horsePricesHtml = pricesHtml[i]\n",
    "        \n",
    "        for b in range(0, len(bookMakerList)):\n",
    "            priceHtml = horsePricesHtml[b]\n",
    "            \n",
    "            if priceHtml[\"data-o\"] == \"\" or priceHtml.has_attr(\"data-ew-denom\") == False:\n",
    "                continue\n",
    "            else:\n",
    "                price = priceHtml[\"data-o\"]\n",
    "                ewDenom = priceHtml[\"data-ew-denom\"]\n",
    "                ewPlaces = priceHtml[\"data-ew-places\"]\n",
    "                bookMakerName = bookMakerList[b]\n",
    "                \n",
    "                finalPrices.append(OddsCheckerPrice(bookMakerName,horseNames[i], price, ewDenom, ewPlaces))\n",
    "                \n",
    "    return finalPrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeOddsCheckerRace(url, bookmakers, log = False):\n",
    "    \n",
    "    options = Options()\n",
    "    user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.517 Safari/537.36'\n",
    "    options.add_argument('user-agent={0}'.format(user_agent))\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),\n",
    "                          options=options)\n",
    "    driver.get(url)\n",
    "    html_source_code = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "    html_soup: BeautifulSoup = BeautifulSoup(html_source_code, 'html.parser')\n",
    "    prettyHTML = html_soup.prettify()\n",
    "    driver.close()\n",
    "    \n",
    "    prices = oddsPortalScraper(prettyHTML, bookmakers,url, log)\n",
    "    \n",
    "    return prices\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httplib2  \n",
    "def scrapeOddsChecker(urlList, bookmakers, log = False):\n",
    "    prices = []\n",
    "    for url in urlList:\n",
    "        #need to add some validation to check whether this url exists, currenty not able to do so..\n",
    "        racePrices = scrapeOddsCheckerRace(url, bookmakers, log)\n",
    "        prices.append(racePrices)\n",
    "        \n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmakers = [\"Bet365\", \"SkyBet\", \"PaddyPower\", \"WilliamHill\", \"888Sport\",\n",
    "             \"Betfair\", \"BetVictor\", \"Coral\", \"UniBet\", \"SpreadEx\", \"BetFred\",\n",
    "             \"BoyleSports\", \"10Bet\", \"BetUk\", \"SportingIndex\", \"LiveScoreBet\",\n",
    "             \"QuinnBet\", \"BetWay\", \"LadBrokes\", \"PariMatch\", \"VBet\", \"SBK\", \"Tote\",\n",
    "             \"BetFairExchange\", \"Smarkets\", \"MatchBook\"]\n",
    "\n",
    "urlList = [\"https://www.oddschecker.com/horse-racing/2022-11-21-kempton/13:50/winner\",\n",
    "           \"https://www.oddschecker.com/horse-racing/2022-11-21-wagga/03:25/winner\"]\n",
    "\n",
    "prices = scrapeOddsChecker(urlList, bookmakers, False)\n",
    "#prices = scrapeOddsCheckerRace(\"https://www.oddschecker.com/horse-racing/2022-11-21-kempton/13:50/winner\", bookmakers, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
